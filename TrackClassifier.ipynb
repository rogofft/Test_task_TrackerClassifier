{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'event_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_to_data, sep=';', names=['id', 'date', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert String format of 'date' to datetime format\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackAnalyzer:\n",
    "    def __init__(self, cluster_distance_thd=0.05, home_job_distance=0.2, label_filter_thd=2):\n",
    "        # Distance for agglomerative clustering\n",
    "        self.cluster_distance_thd = cluster_distance_thd\n",
    "        # Minimum distance between home and job\n",
    "        self.home_job_distance = home_job_distance\n",
    "        # Minimum amount of points in clusters\n",
    "        self.label_filter_thd = label_filter_thd\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean_distance(x1, y1, x2, y2):\n",
    "        return np.sqrt(np.power(x1 - x2, 2) + np.power(y1 - y2, 2))\n",
    "    \n",
    "    def extract_coordinates_by_hours(self, data, hours) -> list:\n",
    "        \"\"\"Group data by hours and calculate average coordinate per hour\"\"\"\n",
    "        coordinates = []\n",
    "        for h in hours:\n",
    "            hour_data = data[data.date.apply(lambda x: x.hour == h)]\n",
    "            if not hour_data.empty:\n",
    "                coordinates.append((hour_data.x.mean(), hour_data.y.mean()))\n",
    "        return coordinates\n",
    "    \n",
    "    def get_labels(self, data):\n",
    "        \"\"\"Find clusters and return labels\"\"\"\n",
    "        return AgglomerativeClustering(n_clusters=None,\n",
    "                                       affinity='euclidean',\n",
    "                                       compute_full_tree=True,\n",
    "                                       linkage='ward',\n",
    "                                       distance_threshold=self.cluster_distance_thd\n",
    "                                       ).fit(data).labels_\n",
    "    \n",
    "    def filter_clusters(self, data):\n",
    "        \"\"\"Filter clusters with threshold\"\"\"\n",
    "        filtered_labels = [index for index, count in data.label.value_counts().iteritems()\n",
    "                           if count >= self.label_filter_thd]\n",
    "        return data[data.label.apply(lambda x: x in filtered_labels)]\n",
    "        \n",
    "    def predict(self, data):\n",
    "        \"\"\"Use this function to classificate tracker's data\"\"\"\n",
    "        data_home = pd.DataFrame(self.extract_coordinates_by_hours(data, range(0, 9)), columns=['x', 'y'])\n",
    "        data_job = pd.DataFrame(self.extract_coordinates_by_hours(data, range(11, 18)), columns=['x', 'y'])\n",
    "        data_after = pd.DataFrame(self.extract_coordinates_by_hours(data, range(20, 24)), columns=['x', 'y'])\n",
    "        \n",
    "        # if no data for clustering\n",
    "        if not (len(data_job) > 1 and len(data_home) > 1 and len(data_after) > 1):\n",
    "            return 0\n",
    "        \n",
    "        # get clusters\n",
    "        data_home['label'] = self.get_labels(data_home)\n",
    "        data_job['label'] = self.get_labels(data_job)\n",
    "        data_after['label'] = self.get_labels(data_after)\n",
    "        \n",
    "        # remove clusters with only 1 elements (most likely it's the way to work)\n",
    "        data_home = self.filter_clusters(data_home)\n",
    "        data_job = self.filter_clusters(data_job)\n",
    "        data_after = self.filter_clusters(data_after)\n",
    "        \n",
    "        # check for only one cluster must be in each group and distance between home, job and after_job\n",
    "        if data_job.label.nunique() == 1 and \\\n",
    "           data_home.label.nunique() == 1 and \\\n",
    "           data_after.label.nunique() == 1 and \\\n",
    "           TrackAnalyzer.euclidean_distance(data_home.x.mean(), data_home.y.mean(),\n",
    "                                            data_job.x.mean(), data_job.y.mean()) > self.home_job_distance and \\\n",
    "           TrackAnalyzer.euclidean_distance(data_home.x.mean(), data_home.y.mean(),\n",
    "                                            data_after.x.mean(), data_after.y.mean()) < self.home_job_distance:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance\n",
    "tracker = TrackAnalyzer()\n",
    "\n",
    "# Make dict from data - id: prediction\n",
    "results = { id_ctr: tracker.predict(data[data.id == id_ctr]) for id_ctr in set(data.id) }\n",
    "# Convert to pandas.Series\n",
    "results_series = pd.Series(results, name='prediction')\n",
    "# Save as csv\n",
    "results_series.to_csv('results.csv', index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
